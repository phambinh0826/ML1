{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Traditional Machine Learning on Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a traditional ML pipeline such as Logistic regression, Random Forest, and Neural\n",
    "networks, the model is first trained on features of a graph and then the model can be\n",
    "applied on a new graph. Using effective features over graphs is the key to achieving good\n",
    "model performance. For simplicity, in this section we focus on un-directed graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Node-Level Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple example of node-level task is node classification based on a few samples. It is\n",
    "illustrated in Figure 1.2\n",
    "\n",
    "A couple different measures characterise the structure and position of a node on a graph:\n",
    "\n",
    "**Node degree:** Number of neighbours\n",
    "\n",
    "**Node centralities:** A measure of the “importance” of a node in a graph. There\n",
    "several different types of centrality.\n",
    "- **Eigenvector centrality:** A node is important if it is surrounded by important\n",
    "neighbouring nodes. We define the centrality of node v as the centrality of\n",
    "neighbouring nodes. This leads to a set of $|N|$ simultaneous linear equations:\n",
    "$$\n",
    "c_v := \\frac{1}{\\lambda} \\sum_{u \\in N(v)} c_u \\quad \\Longleftrightarrow \\quad \\lambda c = Ac\n",
    "$$\n",
    "where $λ$ is a normalisation constant and $A$ is the adjacency matrix of the graph.\n",
    "By Perron-Forbenius Theorem, the largest eigenvalue $\\lambda_{\\text{max}}$ is always positive\n",
    "and unique, and its corresponding eigenvectors can be used for centrality.\n",
    "When $λ$ is the second-largest eigenvalue, $c_v$ has a different meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![f4](f4.jpeg)\n",
    "\n",
    "> Figure 1.3: Examples of clustering coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Betweenness centrality:** A node is important if it is a gatekeeper. i.e. when\n",
    "it lies on many shortest paths between other nodes.\n",
    "\n",
    "$$\n",
    "c_j = \\sum_{s \\neq t \\neq j} \\frac{|\\text{{shortest paths between }} s \\text{{ and }} t \\text{{ containing }} j|}{|\\text{{shortest paths between }} s \\text{{ and }} t|}\n",
    "$$\n",
    "This is important for social networks.\n",
    "\n",
    "- **Closeness Centrality**:\n",
    "  $$\n",
    "  c_v := \\frac{1}{\\sum_{u \\neq v} [\\text{{shortest paths between }} u \\text{{ and }} v]}\n",
    "  $$\n",
    "\n",
    "- **Clustering Coefficients:** How connected \\( v \\)'s neighbouring nodes are:\n",
    "  $$\n",
    "  e_v := \\frac{1}{{\\binom{k_v}{2}}} |\\{\\text{{edges among }} N(v)\\}| \\in [0, 1]\n",
    "  $$\n",
    "Social networks have a huge amount of clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering co¨efficient counts the number of triangles in the **ego-network** (the network\n",
    "formed by ${v} ∪ N(v)$, where $v$ is the ego). We can generalise the above by counting\n",
    "graphlets.\n",
    "An **induced graph** is a graph formed by taking a subset of vertices in a larger graph such\n",
    "that only edges connecting the remaining vertices are preserved.\n",
    "Two graphs with identical topologies are **isomorphic**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![f5](f5.jpeg)\n",
    "\n",
    "> Figure 1.4: Different levels of features distinguish nodes in different ways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Graphlets** are small subgraphs that describe the structure of u’s neighbourhood network.\n",
    "Specifically, they are *rooted, connected, induced, non-isomorphic* subgraphs. Considering\n",
    "graphs of size 2 to 5 nodes we get a vector of 73 (number of graphlets with 2 to 5 vertices)\n",
    "elements that describes the topology of a node’s neighbourhood. This vector is the\n",
    "**graphlet degree vector (GDV)** of a node.\n",
    "\n",
    "The features we have discussed so far capture local topological properties of the graph but\n",
    "cannot distinguish points in a global scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Link-Level Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two formulations of link-level prediction\n",
    "- Links missing at random: Remove a random set of links and then aim to predict\n",
    "them.</br>\n",
    "    e.g. drug interactions\n",
    "- Links over time: Given $G[t_0, t'_0]$ a graph defined by edges up to time $t'0$ output a\n",
    "rankd list L of edges that are predicted to appear in time $G[t_1, t'_1]$. </br>\n",
    "    Evaluation: $n = |Enew|$: number of new edges that appear during the test period.\n",
    "Methodology: For each pair of nodes $x, y$ compute a distance $c(x, y)$ and predict top\n",
    "n elements as links.\n",
    "\n",
    "A couple measures exist for local neighbourhood overlap:\n",
    "\n",
    "- **Common neighbours**:\n",
    "  $$\n",
    "  c(u, v) := |N(v_1) \\cap N(v_2)|\n",
    "  $$\n",
    "\n",
    "- **Jaccard’s Coefficient**:\n",
    "  $$\n",
    "  c(u, v) := \\frac{|N(v_1) \\cap N(v_2)|}{|N(v_1) \\cup N(v_2)|}\n",
    "  $$\n",
    "\n",
    "- **Adamic-Adar Index**:\n",
    "  $$\n",
    "  c(u, v) := \\sum_{u \\in N(v_1) \\cap N(v_2)} \\frac{1}{k_u}\n",
    "  $$\n",
    "  The problem with the three indices above is that they are always 0 if $u, v$ do not share a neighbour.\n",
    "\n",
    "- **Katz Index**:\n",
    "  $$\n",
    "  c(u, v) := \\text{[All walks of all lengths between } u \\text{ and } v\\text{]}\n",
    "  $$\n",
    "  This can be computed by powers of the adjacency matrix. The matrix counting all walks of length \\( n \\) between vertices is $A^n$, so the Katz index can be computed by:\n",
    "  $$\n",
    "  C := \\sum_{i=1}^{\\infty} \\beta^i A^i = (I - \\beta A)^{-1} - I\n",
    "  $$\n",
    "  where the $\\beta < 1$ decay factor is necessary to prevent **$C$** from blowing up to  $+\\infty$. An analogous definition exists for directed graphs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Graph Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of graph kernels is to create a feature vector for the entire graph.\n",
    "\n",
    "**Kernel methods** are widely used for traditional ML for graph-level prediction. Instead of\n",
    "designing feature vectors, we design kernels:\n",
    "- $k(G,G′) ∈ R$\n",
    "- Kernel matrix **$K$** $= [K(G,G')]_{G,G'}$ must always be positive semi-definite.\n",
    "- There exists a feature representation $ϕ$ such that $K(G,G') = ϕ(G)ϕ(G')$ which can\n",
    "even be infinite-dimensional.\n",
    "\n",
    "We could use a *bag-of-words (BOW)* for a graph. Recall that in NLP, BoW simply uses the\n",
    "word count as features for documents with no ordering being considered. We regard nodes\n",
    "as a word.\n",
    "\n",
    "**Graph-Level Graphlet** features counts the number of different graphlets in a graph.\n",
    "The graphlets here are not rooted and do not have to be connected. This definition of\n",
    "graphlet is slightly different from the definition of node level features. A limitation of this\n",
    "definition is that counting graphlets is expensive. Counting size-k gfor a raph with size n\n",
    "by enumeration takes time $O(n^k)$ due to costly subgraph isomorphism tests. If a graph’s\n",
    "node has bounded degree the time could be compressed down to $O(nd^{k−1})$.\n",
    "so far we have only considered features related to the graph structure and not considered\n",
    "the attributes of nodes and their neighbours."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
